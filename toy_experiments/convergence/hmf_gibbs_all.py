"""
Recover the toy dataset generated by code/generate_toy/generate_hmf.py using 
Gibbs, using all datasets.

We can plot the MSE, R2 and Rp as it converges.
"""

project_location = "/home/tab43/Documents/Projects/libraries/"
import sys
sys.path.append(project_location)
from HMF.code.models.hmf_Gibbs import HMF_Gibbs

import numpy, matplotlib.pyplot as plt

##########

''' Model settings '''
settings = {
    'priorF'  : 'exponential',
    'priorG'  : 'normal',
    'priorSn' : 'normal',
    'priorSm' : 'exponential',
    'orderF'  : 'columns',
    'orderG'  : 'columns',
    'orderSn' : 'rows',
    'orderSm' : 'individual',
    'ARD'     : True,
    'importance_learning' : True,
}
hyperparameters = {
    'alphatau' : 1.,
    'betatau'  : 1.,
    'alpha0'   : 0.001,
    'beta0'    : 0.001,
    'alphaS'   : 1.,
    'betaS'    : 1.,
    'alphaA'   : 10000.,
    'betaA'    : 10000.,
    'lambdaF'  : 0.1,
    'lambdaG'  : 0.1,
    'lambdaSn' : 0.1,
    'lambdaSm' : 0.1
}
init = {
    'F'       : 'kmeans',
    'G'       : 'least',
    'Sn'      : 'least',
    'Sm'      : 'random',
    'lambdat' : 'exp',
    'tau'     : 'exp'
}

iterations, burn_in, thinning = 100, 80, 2

N,M,L = 2,1,2
E = [1,2]
I = {1:100,2:80}
K = {1:20, 2:15}
J = [150, 100]

alpha_n = [1., 1.]
alpha_m = [1.]
alpha_l = [1., 1.]


''' Load in data '''
input_folder = project_location+"HMF/toy_experiments/data/"

R_main =    numpy.loadtxt(input_folder+"R_0.txt")
R_second =  numpy.loadtxt(input_folder+"R_1.txt")
C_1 =       numpy.loadtxt(input_folder+"C_0.txt")
D_1 =       numpy.loadtxt(input_folder+"D_0.txt")
D_2 =       numpy.loadtxt(input_folder+"D_1.txt")

Mn_main =   numpy.ones((I[1],I[2]))
Mn_second = numpy.ones((I[1],I[2]))
Mm_1 =      numpy.ones((I[1],I[1]))
Ml_1 =      numpy.ones((I[1],J[0]))
Ml_2 =      numpy.ones((I[2],J[1]))

R = [
    (R_main,   Mn_main,   1, 2, alpha_n[0]),
    (R_second, Mn_second, 1, 2, alpha_n[1])
]
C = [
    (C_1,      Mm_1,      1,    alpha_m[0])
]
D = [
    (D_1,      Ml_1,      1,    alpha_l[0]),
    (D_2,      Ml_2,      2,    alpha_l[1])
]


''' Give the same random initialisation '''
numpy.random.seed(3)


''' Run the Gibbs sampler '''
HMF = HMF_Gibbs(R,C,D,K,settings,hyperparameters)
HMF.initialise(init)
HMF.run(iterations)

iterations_all_taun = HMF.iterations_all_taun
iterations_all_taum = HMF.iterations_all_taum
iterations_all_taul = HMF.iterations_all_taul

iterations_all_alphan = HMF.iterations_all_alphan
iterations_all_alpham = HMF.iterations_all_alpham
iterations_all_alphal = HMF.iterations_all_alphal


'''Plot tau against iterations to see that it converges '''
f, axarr = plt.subplots(5, 2, sharex='col')
x = range(1,len(iterations_all_taun[0])+1)
axarr[0][0].set_title('Convergence of values')
axarr[0][0].plot(x, iterations_all_taun[0])    
axarr[0][0].set_ylabel("taun_1")
axarr[1][0].plot(x, iterations_all_taun[1]) 
axarr[1][0].set_ylabel("taun_2")
axarr[2][0].plot(x, iterations_all_taum[0]) 
axarr[2][0].set_ylabel("taum_1")
axarr[3][0].plot(x, iterations_all_taul[0]) 
axarr[3][0].set_ylabel("taul_1")
axarr[4][0].plot(x, iterations_all_taul[1]) 
axarr[4][0].set_ylabel("taul_2")
axarr[0][1].plot(x, iterations_all_alphan[0])   
axarr[0][1].yaxis.set_label_position("right") 
axarr[0][1].set_ylabel("alphan_1")
axarr[1][1].plot(x, iterations_all_alphan[1])  
axarr[1][1].yaxis.set_label_position("right") 
axarr[1][1].set_ylabel("alphan_2")
axarr[2][1].plot(x, iterations_all_alpham[0])  
axarr[2][1].yaxis.set_label_position("right") 
axarr[2][1].set_ylabel("alpham_1")
axarr[3][1].plot(x, iterations_all_alphal[0]) 
axarr[3][1].yaxis.set_label_position("right")  
axarr[3][1].set_ylabel("alphal_1")
axarr[4][1].plot(x, iterations_all_alphal[1])  
axarr[4][1].yaxis.set_label_position("right") 
axarr[4][1].set_ylabel("alphal_2")
axarr[4][0].set_xlabel("Iterations")
axarr[4][1].set_xlabel("Iterations")

# Extract the performances across all iterations
print "all_performances_Rn = %s" % HMF.all_performances_Rn
print "hmf_data = %s" % HMF.all_performances_Rn['MSE'][0]
